#!/usr/bin/env bash

# This file is part of CO𝘕CEPT, the cosmological 𝘕-body code in Python.
# Copyright © 2015–2018 Jeppe Mosgaard Dakin.
#
# CO𝘕CEPT is free software: You can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# CO𝘕CEPT is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with CO𝘕CEPT. If not, see http://www.gnu.org/licenses/
#
# The author of CO𝘕CEPT can be contacted at dakin(at)phys.au.dk
# The latest version of CO𝘕CEPT is available at
# https://github.com/jmd-dk/concept/



# This script runs the CO𝘕CEPT code.
# Run the script with the -h option to get help.

# Unless this file is being sourced,
# automatically export all variables when set.
being_sourced="True"
if [ "${BASH_SOURCE[0]}" == "${0}" ]; then
    being_sourced="False"
fi
if [ "${being_sourced}" == "False" ]; then
    set -a
fi

# If this file is being sourced, backups of 'this_file' and 'this_dir'
# is needed not to alter the values of these variables.
this_file_backup="${this_file}"
this_dir_backup="${this_dir}"

# Absolute paths to this file and its directory
this_file="$(readlink -f "${BASH_SOURCE[0]}")"
this_dir="$(dirname "${this_file}")"

# The user's current working directory
if [ -z "${workdir}" ]; then
    workdir="$(pwd)"
fi

# For the terminal to be able to print Unicode characters correctly,
# the terminal character set needs to be compatible. To ensure this,
# we set all locale settings to en_US.UTF-8.
export LC_ALL="en_US.UTF-8"
export LANG="en_US.UTF-8"
# Set the terminal if unset or broken
if [ -z "${TERM}" ] || [ "${TERM}" == "dumb" ]; then
    export TERM="linux"
fi

# ANSI/VT100 escape sequences
esc="\x1b"
esc_normal="${esc}[0m"
esc_bold="${esc}[1m"
esc_italic="${esc}[3m"
esc_no_italic="${esc}[23m"
esc_red="${esc}[91m"

# Load paths from the .paths file
curr="${this_dir}"
while :; do
    if [ -f "${curr}/.paths" ]; then
        source "${curr}/.paths"
        break
    fi
    if [ "${curr}" == "/" ]; then
        # Print out error message and exit
        printf "${esc_bold}${esc_red}Could not find the .paths file!${esc_normal}\n" >&2
        exit 1
    fi
    curr="$(dirname "${curr}")"
done

# Load environment variables from the .env file
source "${env_file}"

# The time before any computation begins.
# This time is saved both in seconds after the Unix epoch
# and in a human readable format.
read -r start_time_epoch start_time_human <<<$("${python}" -B -c "
import datetime
t = datetime.datetime.now()
print(t.timestamp(), str(t).replace(' ', '_'))
")

# Check whether this script is run locally or remotely via ssh
ssh="True"
if [ -z "${SSH_CLIENT}" ] && [ -z "${SSH_TTY}" ]; then
    ssh="False"
fi

# Function for printing colored messages
colorprint()
{
# Arguments: Message, color
"${python}" -B -c "
import sys
from blessings import Terminal
terminal = Terminal(force_styling=True)
print(terminal.bold_${2}('${1}'), file=(sys.stderr if '${2}' == 'red' else sys.stdout))"
}

# Function for printing out a nice CO𝘕CEPT logo
print_logo()
{
    logo='
   ____     ____             __  ____    _____   ____   _____
  / __ \   / __ \     /\    / / / __ \  |  ___| |  _ \ |_   _|
 | /  \_| | /  \ |   /  \  / / | /  \_| | |__   | |_) |  | |
 ||    _  ||    ||  / /\ \/ /  ||    _  |  __|  |  __/   | |
 | \__/ | | \__/ | / /  \  /   | \__/ | | |___  | |      | |
  \____/   \____/ /_/    \/     \____/  |_____| |_|      |_|
═══════════════════════════════════════════════════════════════
'
    # Plot the logo via Python's matplotlib.
    # This uses up the the 16th and 17th color of the terminal.
    "${python}" -B -c "
import numpy as np, matplotlib
# Apply colormap
colors = ([0.09, 0.84, 0.05], [0.98, 0.47, 0.20])
for i, color in enumerate(colors):
    colorhex = matplotlib.colors.rgb2hex(color)
    print('\\x1b]4;{};rgb:{}/{}/{}\\x1b\\\\'
           .format(16 + i, colorhex[1:3], colorhex[3:5], colorhex[5:]), end='')
# Construct the colored logo
logo='''${logo}'''
logo = logo[1:-1]
rows = logo.split('\\n')
ANSI = []
for i, row in enumerate(rows):
    for j, c in enumerate(row):
        colornumber = 17 if i < 6 and 17 < j < 31 else 16
        ANSI.append('\\x1b[38;5;{}m{}'.format(colornumber, c))
    ANSI.append('\\x1b[0m\\n')
# Print the ANSI image
print(''.join(ANSI), end='', flush=True)
     "
}
# Print out the logo the first time an execution reaches this point
if [ "${logo_printed}" != "True" ] && [ "${being_sourced}" == "False" ]; then
    print_logo
    export logo_printed="True"
fi

# Function for converting paths to absolute paths
absolute_path()
{
    # Arguments: Path, [working directory]
    local path="${1}"
    currdir="$(pwd)"
    if [ -n "${2}" ]; then
        cd "${2}"
    fi
    # Places backslashes before spaces.
    # These are needed when expanding tilde, but they will not persist.
    path="${path//[ ]/\\ }"
    # Expand tilde
    eval path="${path}"
    # Convert to absolute path
    path=$(readlink -m "${path}")
    if [ -z "${path}" ]; then
        colorprint "Cannot convert \"${1}\" to an absolute path!" "red"
        exit 1
    fi
    cd "${currdir}"
    # Print out result
    echo "${path}"
}

# Function for converting an absolute path to its "sensible" form.
# That is, this function returns the relative path with respect to the
# concept directory, if it is no more than one directory above the
# concept directory. Otherwise, return the absolute path back again.
sensible_path()
{
"${python}" -B -c "
path = '${1}'
from os.path import relpath
rel = relpath(path, '${concept_dir}')
print(path if rel.startswith('../../') else rel)"
}

# Function which prints the absolute path of a given command.
# If the command is not an executable file on the PATH but instead a
# known function, the input command is printed as is. If the command
# cannot be found at all, nothing is printed and an exit code of 1
# is returned.
get_command()
{
    command_name="${1}"
    # Use the type builtin to locate the command
    path="$(type "${command_name}" 2>/dev/null | awk '{print $NF}')"
    if [[ "${path}" == "/"* ]]; then
        # The command is a path
        path="$(readlink -f "${path}")"
        echo "${path}"
        return 0
    elif [ -n "${path}" ]; then
        # The command exists as a function
        echo "${command_name}"
        return 0
    fi
    # The command does not exist
    return 1
}

# Function which prints a passed Bash array
# in the format of a Python list.
bash_array2python_list()
{
    # Call like this: bash_array2python_list "${array[@]}"
    local list=''
    local element
    for element in "$@"; do
        # If element is a string, encapsulate it in quotation marks
        element=$("${python}" -B -c "
try:
    eval(\"${element}\")
    print(\"${element}\")
except:
    print('\"{}\"'.format(\"${element}\"))
")
        # Append element to list
        list="$(echo "${list}")${element}, "
    done
    list="[$(echo "${list}")]"
    echo "${list}"
}

# Add the concept directory to searched paths
# when importing modules in Python.
export PYTHONPATH="${concept_dir}:${PYTHONPATH}"

# On some systems, libpng finds a wrong version of the zlib shared
# library. To fix this we export the zlib library at run time.
export LD_LIBRARY_PATH="${zlib_dir}/lib:${LD_LIBRARY_PATH}"

# The MPI executables and libraries should be
# on the PATH and LD_LIBRARY_PATH, respectively.
export PATH="${mpi_dir}/bin:${PATH}"
export LD_LIBRARY_PATH="${mpi_dir}/lib:${LD_LIBRARY_PATH}"

# Determine the MPI implentation and version
if [ -f "${mpi_dir}/bin/ompi_info" ]; then
    mpi_implementation="openmpi"
    mpi_version="$("${mpiexec}" --version | head -n 1 | awk '{print $NF}')"
elif [ -f "${mpi_dir}/bin/mpichversion" ]; then
    mpi_implementation="mpich"
    mpi_version="$("${mpi_dir}/bin/mpichversion" | head -n 1 | awk '{print $NF}')"
else
    mpi_implementation="unknown"
    mpi_version="unknown"
fi

# MPI implementation specifics
mpiexec_args=""
if [ "${mpi_implementation}" == "openmpi" ]; then
    # Extra arguments to pass to OpenMPI's mpiexec.
    # By default, newer versions of OpenMPI binds processes to sockets
    # (for nprocs > 2), which means that OpenMP threads are not
    # necessarily assigned to cores in a one-to-one fashion.
    # Fix this by simply removing this binding.
    mpiexec_args="${mpiexec_args} --bind-to none"
    # In OpenMPI 3, oversubscription (having more MPI processes than
    # physical cores) is disallowed by default.
    if [[ "${mpi_version}" == 3* ]]; then
        mpiexec_args="${mpiexec_args} --oversubscribe"
    fi
    # Disable aggregation of OpenMPI warnings.
    export OMPI_MCA_orte_base_help_aggregate=0
    # Disable OpenMPI warning about forking
    export OMPI_MCA_mpi_warn_on_fork=0
    # If OpenMPI complains about openib, it may be having problems
    # with infiniband. Try adding "-mca btl ^openib" to mpiexec_args.
    # Note that --prefix should not be used,
    # as the absolute path to mpiexec is given.
elif [ "${mpi_implementation}" == "mpich" ]; then
    # Extra arguments to pass to MPICH's mpiexec
    :
fi

# Function which prints the resource manager.
# In order, the implemented resource managers are:
# - Slurm
# - TORQUE/PBS
get_resource_manager()
{
    # Detect what resource manager is used
    if get_command sbatch >/dev/null; then
        # Slurm is installed. Use this as the resource manager.
        resource_manager="slurm"
    elif get_command qsub >/dev/null; then
        # TORQUE/PBS is installed. Use this as the resource manager.
        resource_manager="torque"
    else
        # No resource manager found
        resource_manager=""
    fi
    echo "${resource_manager}"
}

# If this file is being sourced, return now
if [ "${being_sourced}" == "True" ]; then
    this_file="${this_file_backup}"
    this_dir="${this_dir_backup}"
    return
fi

# Set up error trapping
ctrl_c()
{
    trap : 0
    exit 2
}
abort()
{
    colorprint "An error occurred!" "red"
    if [ -n "${exit_code}" ]; then
        exit ${exit_code}
    else
        exit 1
    fi
}
trap 'ctrl_c' SIGINT
trap 'abort' EXIT
set -e

# Default values of command-line arguments
interactive_default="False"
local_default="False"
main_default="${concept_dir}/main.py"
memory_default=0  # 0 implies unset
no_watch_default="False"
no_optimization_default="False"
nprocs_default=1
params_default="None"
pure_python_default="False"
unsafe_build_default="False"
walltime_default="00:00:00"  # 00:00:00 implies unset

# Initial but illegal values of some command-line arguments,
# for testing whether these arguments have been supplied.
nprocs_unspecified="-1"
params_unspecified="__none__"
queue_unspecified="__none__"
test_unspecified="__none__"
utility_unspecified="__none__"

# Change to the concept code directory
cd "${concept_dir}"

# Use Python's argparse module to handle command-line arguments
argparse_finished="no"
args=$("${python}" -B -c "
import argparse, math, re, sys
# Function which checks whether input is a representation of
# a positive integer and converts it.
def positive_int(value):
    value_raw = value
    def raise_argparse_exception():
        raise argparse.ArgumentTypeError(\"invalid positive int value: '{}'\".format(value_raw))
    try:
        value = float(eval(value))
    except:
        raise_argparse_exception()
    if value != int(value):
        raise_argparse_exception()
    value = int(value)
    if value < 1:
        raise_argparse_exception()
    return value
# Function which checks whether input is a representation of
# one or two positive integers. If two ints are given,
# separate them by a colon.
def positive_int_or_int_pair(value):
    value_raw = value
    def raise_argparse_exception():
        raise argparse.ArgumentTypeError(\"invalid positive int or int pair: '{}'\"
                                         .format(value_raw))
    for sep in ' ,;':
        value = value.replace(sep, ':')
    value = [part for part in value.split(':') if part]
    if len(value) > 2:
        raise_argparse_exception()
    try:
        for i, part in enumerate(value):
            value[i] = float(eval(part))
    except:
        raise_argparse_exception()
    for i, part in enumerate(value):
        if part != int(part):
            raise_argparse_exception()
        if part < 1:
            raise_argparse_exception()
        value[i] = str(int(part))
    value = ':'.join(value)
    return value
# Function which checks whether input is a representation of
# a memory size and converts it to bytes.
def memory(value):
    value_raw = value
    def raise_argparse_exception():
        raise argparse.ArgumentTypeError(\"invalid memory value: '{}'\".format(value_raw))
    # Convert to (whole) bytes
    value = value.lower()
    value = value.replace('b', '')
    value = re.subn('([0-9]+)([a-z]+)', '\g<1>*\g<2>', value)[0]
    units = {'k': 2**10,
             'm': 2**20,
             'g': 2**30,
             't': 2**40,
             'p': 2**50,
             'e': 2**60,
             'z': 2**70,
             'y': 2**80,
             }
    try:
        value = int(math.ceil(float(eval(value, units))))
    except:
        raise_argparse_exception()
    return value
# Function which converts a time value to the format hh:mm:ss
def time(value):
    # Convert value to integer seconds
    units = {'s': 1}
    units['sec'] = units['secs'] = units['seond'] = units['seonds'] = units['s']
    units['m'] = 60*units['s']
    units['min'] = units['mins'] = units['minute'] = units['minutes'] = units['m']
    units['h'] = 60*units['m']
    units['hr'] = units['hrs'] = units['hs'] = units['hour'] = units['hours'] = units['h']
    units['d'] = 24*units['h']
    units['day'] = units['days'] = units['d']
    units['y'] = 365.25*units['d']
    units['yr'] = units['year'] = units['years'] = units['y']
    # If a pure number is provided, interpret this in seconds.
    try:
        value = int(value)*units['s']
    except:
        pass
    # Attempt to interpret the time as an expression
    # like '2hr + 30mins'.
    if isinstance(value, str):
        value = value.lower()
        value = re.subn('([0-9]+)([a-z]+)', '\g<1>*\g<2>', value)[0]
        try:
            value = int(math.ceil(float(eval(value, units))))
        except:
            pass
    # Attempt to interpret the time in the format
    # 'm:s' or 'h:m:s' or 'd:h:m:s' or 'd+h:m:s' or 'd+h:m' or 'd+h'.
    if isinstance(value, str):
        plusses_in_value = value.count('+')
        if plusses_in_value > 1:
            raise argparse.ArgumentTypeError(\"error parsing value\")
        for sep in '+ ,;':
            value = value.replace(sep, ':')
        value = value.split(':')
        s = m = h = d = 0
        if len(value) == 1:
            raise argparse.ArgumentTypeError(\"error parsing value\")
        elif len(value) == 2:
            if plusses_in_value:
                # Format d:h
                d, h = value
            else:
                # Format m:s
                m, s = value
        elif len(value) == 3:
            if plusses_in_value:
                # Format d+h:m
                d, h, m = value
            else:
                # Format h:m:s
                h, m, s = value
        elif len(value) == 4:
            # Format d:h:m:s or d+h:m:s
            d, h, m, s = value
        else:
            raise argparse.ArgumentTypeError(\"error parsing value\")
        d, h, m, s = int(d), int(h), int(m), int(s)
        value = int(math.ceil(s*units['s'] + m*units['m'] + h*units['h'] + d*units['d']))
    # Now value should be in integer seconds
    if value < 0:
        raise argparse.ArgumentTypeError(\"the walltime cannot be negative\")
    # Convert to the format hh:mm:ss.
    h = value//units['h']
    value -= h*units['h']
    m = value//units['m']
    value -= m*units['m']
    s = value
    h, m, s = str(h), str(m), str(s)
    if len(h) == 1:
        h = '0' + h
    if len(m) == 1:
        m = '0' + m
    if len(s) == 1:
        s = '0' + s
    value = f'{h}:{m}:{s}'
    return value
# Setup command-line arguments
parser = argparse.ArgumentParser(
    prog='$(basename "${this_file}")',
    description='Run the CO𝘕CEPT code',
)
parser.add_argument(
    '-i', '--interactive',
    help='inspect interactively after program execution',
    default=${interactive_default},
    action='store_true',
)
parser.add_argument(
    '-m', '--main',
    help='entry point of the code. Can be a Python filename or command.',
    default='${main_default}',
)
parser.add_argument(
    '--memory',
    help='maximum total memory consumption for remote job',
    type=memory,
    default=${memory_default},
)
parser.add_argument(
    '-n', '--nprocs',
    help=('total number of processes '
          'or number of nodes and number of processes per node'),
    type=positive_int_or_int_pair,
    default=${nprocs_unspecified},
)
parser.add_argument(
    '-p', '--params',
    help='parameter file to use',
    default='${params_unspecified}',
)
parser.add_argument(
    '-q', '--queue',
    help='queue for submission of the remote job',
    default='${queue_unspecified}',
)
parser.add_argument(
    '-t', '--test',
    help=('run test TEST. TEST can be any subdirectory of the tests directory. '
          'Use TEST=all to run all tests'),
    default='${test_unspecified}',
)
parser.add_argument(
    '-u', '--utility',
    nargs='+',
    help='run utility UTILITY. UTILITY can be any executable in the utilities directory',
    default=['${utility_unspecified}']*2,  # One for utility, one for utility_args
)
parser.add_argument(
    '-w', '--walltime',
    help='walltime for remote job',
    type=time,
    default='${walltime_default}',
)
parser.add_argument(
    '--local',
    help='force the run to be done locally, without submitting it as a remote job',
    default=${local_default},
    action='store_true',
)
parser.add_argument(
    '--no-optimization',
    help='disable compiler optimizations',
    default=${no_optimization_default},
    action='store_true',
)
parser.add_argument(
    '--no-watch',
    help='do not follow the submitted job via the watch utility',
    default=${no_watch_default},
    action='store_true',
)
parser.add_argument(
    '--pure-python',
    help='run in pure Python mode',
    default=${pure_python_default},
    action='store_true',
)
parser.add_argument(
    '--unsafe-build',
    help='ignore dependencies between modules when building',
    default=${unsafe_build_default},
    action='store_true',
)
# Enables Python to write directly to screen (stderr)
# in case of help request.
stdout_copy = sys.stdout
sys.stdout = sys.stderr
# Now do the actual argument parsing,
# including writing out the help message.
args, unknown_args = parser.parse_known_args()
# If a utility is to be used, arguments unknown to this script should
# be passed on to the utility.
utility_args = args.utility[1:]
if args.utility[0] != '${utility_unspecified}':
    utility_args += unknown_args
else:
    # Do print out error if invalid arguments are given
    # and no utility should be used.
    args = parser.parse_args()
# Reset stdout
sys.stdout = stdout_copy
# Print out the arguments.
# These will be captured in the Bash 'args' variable
print(  '  argparse_finished=yes'
      + '; interactive={}'.format(args.interactive)
      + '; main=\"{}\"'.format(args.main)
      + '; memory=\"{}\"'.format(args.memory)
      + '; nprocs={}'.format(args.nprocs)
      + '; params=\"{}\"'.format(args.params)
      + '; queue={}'.format(args.queue)
      + '; test=\"{}\"'.format(args.test)
      + '; utility=\"{}\"'.format(args.utility[0])
      + '; utility_args=({})'.format(\"'\" + \"' '\".join(utility_args) + \"'\")  # Bash array
      + '; walltime={}'.format(args.walltime)
      + '; local={}'.format(args.local)
      + '; no_optimization={}'.format(args.no_optimization)
      + '; no_watch={}'.format(args.no_watch)
      + '; pure_python={}'.format(args.pure_python)
      + '; unsafe_build={}'.format(args.unsafe_build)
      )
" "$@" || :)
# Evaluate the handled arguments into this scope
eval "${args}"
# Exit if argparse exited without finishing
if [ "${argparse_finished}" != "yes" ]; then
    trap : 0
    exit 0
fi

# Display warning if the required memory is below one megabyte
if [ ${memory} -gt 0 ] && [ ${memory} -lt 1048576 ]; then
    colorprint "Warning: The required memory is below 1 MB. \
Have you forgotten to specify the unit?" "red"
fi

# Display warning if the requested walltime is below one minute
if [ "${walltime}" != "00:00:00" ] && [[ "${walltime}" == "00:00:"* ]]; then
    colorprint "Warning: The requested walltime is below 1 minute. \
Have you forgotten to specify the unit?" "red"
fi

# Check whether the main "file" is really a string of commands
main_as_command="no"
if (   [[ "${main}" == *"print("* ]] \
    || [[ "${main}" == *";"*      ]] \
    || [[ "${main}" == *$'\n'*    ]]); then
    main_as_command="yes"
fi

# Convert all supplied paths to absolute paths
if [ "${main_as_command}" == "no" ]; then
    main="$(absolute_path "${main}")"
fi
if [ "${params}" != "${params_unspecified}" ]; then
    params="$(absolute_path "${params}")"
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ]; then
    test="${tests_dir}/$(basename "${test}")"
fi
if [ "${utility}" != "${utility_unspecified}" ]; then
    utility="${utilities_dir}/$(basename "${utility}")"
fi

# Function for doing fuzzy comparisons between
# illegal concept options and possible correct ones.
concept_options=("$@")
suggest_correct_invocation()
{
    # First argument: The illegal option
    # Second argument: The option type ('test' or 'utility')
    illegal_option="$(basename "$1")"
    invocation="$0"
    for arg in "${concept_options[@]}"; do
        if [ "${replace_next}" == "True" ]; then
            invocation="${invocation} __replace__"
            replace_next="False"
        else
            invocation="${invocation} ${arg}"
        fi
        if    (   [ "$2" == "test"    ] \
               && ([ "${arg}" == "-t" ] || [ "${arg}" == "--test" ])) \
           || (   [ "$2" == "utility" ] \
               && ([ "${arg}" == "-u" ] || [ "${arg}" == "--utility" ])); then
            replace_next="True"
        fi
    done
    "${python}" -B -c "
import difflib, shutil, os
if '$2' == 'test':
    files = os.listdir('${tests_dir}')
    possibilities = [file for file in files if os.path.isdir('${tests_dir}/' + file)]
elif '$2' == 'utility':
    files = os.listdir('${utilities_dir}')
    possibilities = [file for file in files if shutil.which('${utilities_dir}/' + file)]
max_ratio = 0
for possibility in possibilities:
    ratio = max([
        difflib.SequenceMatcher(a='${illegal_option}', b=possibility).ratio(),
        difflib.SequenceMatcher(a='${illegal_option}'.lower(), b=possibility.lower()).ratio(),
    ])
    if ratio > max_ratio:
        max_ratio = ratio
        closest_match = possibility
if max_ratio > 0.01:
    print('Did you mean:\n${invocation}'.replace('__replace__', closest_match))
                   "
}

# Do the supplied paths exist?
if [ "${main_as_command}" == "no" ] && [ ! -f "${main}" ]; then
    colorprint "Error: Entry point \"${main}\" does not exist!" "red"
    exit 1
fi
if [ "${params}" != "${params_unspecified}" ] && [ ! -f "${params}" ]; then
    colorprint "Error: Parameter file \"${params}\" does not exist!" "red"
    exit 1
fi
if [ "${test}" != "${test_unspecified}" ] && [ "${test}" != "all" ] && [ ! -d "${test}" ]; then
    colorprint "Error: Test \"${test}\" does not exist!" "red"
    # Suggest closest match
    suggest_correct_invocation "${test}" "test"
    exit 1
fi
if [ "${utility}" != "${utility_unspecified}" ] && [ ! -f "${utility}" ]; then
    colorprint "Error: Utility \"${utility}\" does not exist!" "red"
    # Suggest closest match
    suggest_correct_invocation "${utility}" "utility"
    exit 1
fi

# Assigned values to unspecified parameters
if [ "${nprocs}" == "${nprocs_unspecified}" ]; then
    nprocs="${nprocs_default}"
fi
if [ "${params}" == "${params_unspecified}" ]; then
    params="${params_default}"
fi

# If a test is to be run, run it and exit
if [ "${test}" != "${test_unspecified}" ]; then
    # Function which can extract parameters from the parameter file
    # given by "${this_dir}/params". This is used by some tests.
    get_param()
    {
        "${concept}" -n 1                                                    \
                     -p "${this_dir}/params"                                 \
                     -m "from commons import *; print('param_var =', ${1})"  \
                     --pure-python                                           \
                     --local                                                 \
                     | grep "param_var"                                      \
                     | tail -n 1                                             \
                     | sed 's/^.\{12\}//'
    }
    if [ "${test}" == "all" ]; then
        # Find and run all tests
        tests="$(cd "${tests_dir}" && "${python}" -B -c "
from glob import glob
# List tests in order of required execution.
# Tests not included here will be run last.
order = (# Test whether the code is able to compile and run
         'basic',
         # Test of the GADGET installation
         'gadget',
         # Tests of the CLASS installation,
         # the Friedmann equation and the realizations.
         'friedmann',
         'realize',
         # Tests of the particle implementation
         'drift_noHubble',
         'drift',
         'kick_PP_without_Ewald',
         'kick_PP_with_Ewald',
         # Tests of the PP implementation
         'pure_python_PP',
         'concept_vs_gadget_PP',
         'nprocs_PP',
         # Tests of the PM implementation
         'pure_python_PM',
         'concept_vs_gadget_PM',
         'nprocs_PM',
         # Tests of the P³M implementation
         'pure_python_P3M',
         'concept_vs_gadget_P3M',
         'nprocs_P3M',
         # Test of the power spectrum functionality
         'powerspec',
         # Tests of the fluid implementation
         'fluid_drift_rigid_noHubble',
         'fluid_drift_rigid',
         'fluid_gravity_noHubble',
         'fluid_gravity',
         'fluid_vacuum',
         'fluid_vs_particles',
         'fluid_pressure',
         # Test whether the optimizations introduces bugs
         'optimizations',
         # Tests of other functionality
         'render',
         )
# Find all tests (directories in ${tests_dir}).
# Skip test if its (directory) name has a leading underscore.
tests = (dir[:-1] for dir in glob('*/') if not dir.startswith('_'))
# Sort the tests based on the order given above
sorted_tests = sorted(tests, key=lambda test: order.index(test) if test in order else len(order))
for test in sorted_tests:
    print(test)
"              )"
        # Run all tests in the test directory
        echo "The following tests will be run in order:"
        for test_name in ${tests}; do
            echo "    ${test_name}"
        done
        for test_name in ${tests}; do
            start_time_test=$("${python}" -B -c "import time; print(time.time())")
            colorprint "\nRunning ${test_name} test" "yellow"
            "${tests_dir}/${test_name}/run_test"
            colorprint "${test_name} test ran successfully" "green"
            # Print out the execution time for this test
            "${python}" -B -c "from commons import *
print('Total execution time: {}'.format(time_since(${start_time_test})))"
        done
        colorprint "All tests ran successfully" "green"
    else
        # Run specific test
        test_name="$(basename "${test}")"
        colorprint "Running ${test_name} test" "yellow"
        "${test}/run_test"
        colorprint "${test_name} test ran successfully" "green"
    fi
    # Print out the total time it took to ran the test(s)
    "${python}" -B -c "from commons import *
print('Total execution time: {}'.format(time_since(${start_time_epoch})))"
    # Deactivate traps and exit
    trap : 0
    exit 0
fi

# Determine wheter to run CO𝘕CEPT locally or remotely (via some
# resource manager). Always treat tests as if they were run locally.
remote="False"
if [ "${local}" == "False" ] && [ "${test}" == "${test_unspecified}" ] \
                             && [ "${ssh}" == "True" ]; then
    remote="True"
fi

# Cannot run in interactive mode when running remotely
if [ "${remote}" == "True" ] && [ "${interactive}" == "True" ]; then
    colorprint "Cannot run in interactive mode when run remotely" "red"
    exit 1
fi

# If run locally, set the number of OpenMP threads
# equal to the number of MPI processes. When running remotely,
# leave the OMP_NUM_THREADS unset as this will utilise all available
# CPU cores.
if [ "${remote}" != "True" ]; then
    nprocs_per_node="${nprocs}"
    if [[ "${nprocs}" == *':'* ]]; then
        nprocs_per_node=$("${python}" -B -c "print('${nprocs}'[('${nprocs}'.index(':') + 1):])")
    fi
    # Use the same number of OpenMP threads as MPI processes/node,
    # unless OMP_NUM_THREADS is already defined.
    if [ -z "${OMP_NUM_THREADS}" ]; then
        export OMP_NUM_THREADS=${nprocs_per_node}
    fi
fi

# Compile or do cleanup from last compilation.
# The only time where neither should be done
# is when running some particular utilities.
prepare_files="True"
if    [ "$(basename "${utility}")" == "play"   ] \
   || [ "$(basename "${utility}")" == "update" ] \
   || [ "$(basename "${utility}")" == "watch"  ]; then
   prepare_files="False"
fi
if [ "${prepare_files}" == "True" ]; then
    if [ "${pure_python}" == "True" ]; then
        # Rename compiled Cython modules *.so to *.so_
        if ls "${concept_dir}/"*.so > /dev/null 2>&1; then
            (cd "${concept_dir}" && for f in *.so; do
                                        mv "${f}" "${f%.so}.so_"
                                    done
             )
        fi
    else
        # Rename compiled Cython modules *.so_ back to *.so
        # and compile with Cython.
        if ls "${concept_dir}/"*.so_ > /dev/null 2>&1; then
            (cd "${concept_dir}" && for f in *.so_; do
                                        mv "${f}" "${f%.so_}.so"
                                    done
             )
        fi
        # Compile all the modules in parallel.
        # Cython might warn about redeclarations in CythonGSL,
        # which we filter out as we do not want to worry about them.
        (cd "${concept_dir}" && make unsafe_build="${unsafe_build}"         \
                                     no_optimization="${no_optimization}"   \
                                     -j                                     \
                                     2> >(grep -v 'GSL_.* redeclared' 1>&2)
                                     )
    fi
fi

# If a utility is to be run, run it and exit
if [ "${utility}" != "${utility_unspecified}" ]; then
    # If no argument was passed after the -u option,
    # utility_args should be empty.
    if [ "${utility_args}" == '""' ] || [ "${utility_args}" == "''" ]; then
        utility_args=""
    fi
    # Set flag variables for the flag command options,
    # so that a utility can call this script with the same flags enabled
    # as what used to invoke this script originally.
    local_flag=""
    if [ "${local}" == "True" ]; then
        local_flag="--local"
    fi
    interactive_flag=""
    if [ "${interactive}" == "True" ]; then
        interactive_flag="--interactive"
    fi
    no_optimization_flag=""
    if [ "${no_optimization}" == "True" ]; then
        no_optimization_flag="--no-optimization"
    fi
    no_watch_flag=""
    if [ "${no_watch}" == "True" ]; then
        no_watch_flag="--no-watch"
    fi
    pure_python_flag=""
    if [ "${pure_python}" == "True" ]; then
        pure_python_flag="--pure-python"
    fi
    unsafe_build_flag=""
    if [ "${unsafe_build}" == "True" ]; then
        unsafe_build_flag="--unsafe-build"
    fi
    # Run utility and exit
    colorprint "Running the $(basename "${utility}") utility" "yellow"
    trap : 0
    if [ -z "${utility_args[0]}" ] && [ ${#utility_args[@]} == 1 ]; then
        called_from_concept="True" "${utility}"
    else
        called_from_concept="True" "${utility}" "${utility_args[@]}"
    fi
    # Print out the total execution time for this utility
    "${python}" -B -c "from commons import *
print('Total execution time: {}'.format(time_since(${start_time_epoch})))"
    exit 0
fi

# Sensible paths (for clean printout)
if [ "${main_as_command}" == "no" ]; then
    main_rel="$(sensible_path ${main})"
else
    main_rel="${main}"
fi
params_rel="$(sensible_path ${params})"
logs_dir_rel="$(sensible_path ${logs_dir})"

# Make a hidden copy of the parameter file in the params directory.
# This copy will be the parameter file actually used, freeing up the
# supplied parameter file for editing.
# Also make sure that this directory exists.
mkdir -p "${params_dir}"
if [ "${params}" == "${params_default}" ]; then
    params_cp="${params}"
    params_cp_info=""
else
    params_cp="${params_dir}/.params_cp_${start_time_human}"
    cp "${params}" "${params_cp}"
    params_cp_info=" (copied to \"$(sensible_path ${params_cp})\")"
fi

# Create the logs dir if it does not exist
mkdir -p "${logs_dir}"

# Either stop doing further actions, submit job or run it locally
if [ "${remote}" == "True" ]; then
    # Running remotely.
    # The remote job name.
    jobname="CONCEPT:${params_rel}:CONCEPT"
    # Detect what resource manager is used
    resource_manager="$(get_resource_manager)"
    # Prepare job script header dependent on the resource manager.
    # If no resource manager is used, default to slurm.
    if [ "${resource_manager}" == "slurm" ] || [ -z "${resource_manager}" ]; then
        # Split the 'nprocs' variable up into the number of nodes
        # and the number of processes per node, if both are given.
        if [[ "${nprocs}" == *':'* ]]; then
            nnodes=$("${python}" -B -c "print('${nprocs}'[:'${nprocs}'.index(':')])")
            nprocs_per_node=$("${python}" -B -c "print('${nprocs}'[('${nprocs}'.index(':') + 1):])")
            ((nprocs = nnodes*nprocs_per_node))
        else
            nnodes=0  # Has to be 0, not 1
            nprocs_per_node=${nprocs}
        fi
        # Compute dedicated memory per process in megabytes
        mb_per_process=$("${python}" -B -c "print(int(${memory}/(2**20*${nprocs})))")
        # Construct Slurm header
        jobscript_header="$(${python} -B -c "
lines = []
lines.append('#SBATCH --job-name=${jobname}')
lines.append('#SBATCH --partition=${queue}')
if ${nnodes}:
    lines.append('#SBATCH --nodes=${nnodes}')
    lines.append('#SBATCH --tasks-per-node=${nprocs_per_node}')
else:
    lines.append('#SBATCH --ntasks=${nprocs}')
if ${memory}:
    lines.append('#SBATCH --mem-per-cpu=${mb_per_process}M')
if '${walltime}' != '00:00:00':
    lines.append('#SBATCH --time=${walltime}')
lines.append('#SBATCH --output=/dev/null')
lines.append('#SBATCH --error=/dev/null')
lines.append('')
lines.append('# Get the ID of the current job')
lines.append('jobid=\"\${SLURM_JOB_ID%%.*}\"')
print('\n'.join(lines))
        ")"
    elif [ "${resource_manager}" == "torque" ]; then
        # Split the 'nprocs' variable up into the number of nodes
        # and the number of processes per node.
        if [[ "${nprocs}" != *':'* ]]; then
            colorprint "Error: When using TORQUE or PBS you need to specify the number of nodes \
and the number of processes per node" "red"
            exit 1
        fi
        nnodes=$("${python}" -B -c "print('${nprocs}'[:'${nprocs}'.index(':')])")
        nprocs_per_node=$("${python}" -B -c "print('${nprocs}'[('${nprocs}'.index(':') + 1):])")
        ((nprocs = nnodes*nprocs_per_node))
        # Compute dedicated memory per process in megabytes
        mb_per_process=$("${python}" -B -c "print(int(${memory}/(2**20*${nprocs})))")
        # Construct TORQUE header
        jobscript_header="$(${python} -B -c "
lines = []
lines.append('#PBS -N ${jobname}')
lines.append('#PBS -q ${queue}')
lines.append('#PBS -l nodes=${nnodes}:ppn=${nprocs_per_node}')
if ${memory}:
    lines.append('#PBS -l pmem=${mb_per_process}mb')
if '${walltime}' != '00:00:00':
    lines.append('#PBS -l walltime=${walltime}')
lines.append('#PBS -o /dev/null')
lines.append('#PBS -e /dev/null')
lines.append('')
lines.append('# Get the ID of the current job')
lines.append('jobid=\"\${PBS_JOBID%%.*}\"')
print('\n'.join(lines))
        ")"
    fi
    # Prepare text with the total memory consumption
    memory_in_tb=$("${python}" -B -c "print(int(${memory}/(2**40)))")
    memory_in_gb=$("${python}" -B -c "print(int(${memory}/(2**30)))")
    memory_in_mb=$("${python}" -B -c "print(int(${memory}/(2**20)))")
    if [ ${memory_in_tb} -gt 1 ]; then
        memory_display="${memory_in_tb} TB"
    elif [ ${memory_in_gb} -gt 1 ]; then
        memory_display="${memory_in_gb} GB"
    elif [ ${memory_in_mb} -gt 1 ]; then
        memory_display="${memory_in_mb} MB"
    else
        memory_display=""
    fi
    # Write job script file
    jobscript="${this_dir}/jobscript"
    printf "#!/usr/bin/env bash
${jobscript_header}

# Source the concept script
source \"${concept}\"

# Variables
logs_dir=\"${logs_dir}\"
logs_dir_rel=\"${logs_dir_rel}\"
main=\"${main}\"
main_as_command=\"${main_as_command}\"
main_rel=\"${main_rel}\"
memory_display=\"${memory_display}\"
mpiexec_args=\"${mpiexec_args}\"
nnodes=${nnodes}
nprocs=${nprocs}
nprocs_per_node=${nprocs_per_node}
params=\"${params}\"
params_cp=\"${params_cp}\"
params_cp_info=\"${params_cp_info}\"
params_rel=\"${params_rel}\"
pure_python=\"${pure_python}\"

# Change to the logs directory,
# so that autogenerated files will be dumped there.
cd \"\${logs_dir}\"

# Print start messages
if [ \"\${pure_python}\" == \"True\" ]; then
    colorprint \"Running CO𝘕CEPT job \${jobid} in pure Python mode remotely on \$(hostname -f)\" \
               \"yellow\" > \"\${logs_dir}/\${jobid}\"
else
    colorprint \"Running CO𝘕CEPT job \${jobid} remotely on \$(hostname -f)\" \
               \"yellow\" > \"\${logs_dir}/\${jobid}\"
fi
echo \"Entry point:    \\\\\"\${main_rel}\\\\\"\" >> \"\${logs_dir}/\${jobid}\"
if [ \"\${params_rel}\" == \"None\" ]; then
    echo \"Parameter file: \${params_rel}\" >> \"\${logs_dir}/\${jobid}\"
else
    echo \"Parameter file: \\\\\"\${params_rel}\${params_cp_info}\\\\\"\" \
          >> \"\${logs_dir}/\${jobid}\"
fi
echo \"Log file:       \\\\\"\${logs_dir_rel}/\${jobid}\\\\\"\" >> \"\${logs_dir}/\${jobid}\"
if [ -n \"\${memory_display}\" ]; then
    echo \"Memory:         \${memory_display}\" >> \"\${logs_dir}/\${jobid}\"
fi

# Prepare Python options
if [ \"\${main_as_command}\" == \"yes\" ]; then
    # Run main as Python command
    main_as_library=\"\${main}\"
    m_flag=\"-c\"
else
    if [ \"\${pure_python}\" == \"True\" ]; then
        # Run main as normal Python script
        main_as_library=\"\${main}\"
        m_flag=\"\"
    else
        main_as_library=\"\${main%%.*}.so\"
        if [ -f \"\${main_as_library}\" ]; then
            # Run main as compiled library module
            main_as_library=\"\$(basename \"\${main_as_library}\")\"
            m_flag=\"-m\"
        else
            # Run main as normal Python script,
            # even though the CO𝘕CEPT modules are compiled.
            main_as_library=\"\${main}\"
            m_flag=\"\"
        fi
    fi
fi

# Run the code. Both stdout and stderr are being logged
# to logs_dir/jobid, while the stderr alone is also logged
# to logs_dir/jobid_err.
(cd \"\${concept_dir}\" && \"\${mpiexec}\" \${mpiexec_args}                                  \\
                                           \"\${python}\" -B                                 \\
                                                          \${m_flag} \"\${main_as_library}\" \\
                                                          \"params='\${params}'\"            \\
                                                          \"params_cp='\${params_cp}'\"      \\
                                                          \"jobid='\${jobid}'\"              \\
 >> \"\${logs_dir}/\${jobid}\" 2>> >(tee -a \"\${logs_dir}/\${jobid}_err\"))

# Run complete. Do cleanup.
if [ -f \"\${logs_dir}/\${jobid}_err\" ] && [ ! -s \"\${logs_dir}/\${jobid}_err\" ]; then
    # Remove error log if empty
    rm \"\${logs_dir}/\${jobid}_err\"
else
    colorprint \"\\\nSome warnings/errors occured during CO𝘕CEPT run!\" \"red\" \
               >> \"\${logs_dir}/\${jobid}\" 2>&1
    colorprint \"Check the following error log for more information:\"  \"red\" \
               >> \"\${logs_dir}/\${jobid}\" 2>&1
    colorprint \"\\\\\"\${logs_dir}/\${jobid}_err\\\\\"\"               \"red\" \
               >> \"\${logs_dir}/\${jobid}\" 2>&1
fi
" > "${jobscript}"
    # Exit now if no resource manager was found
    if [ -z "${resource_manager}" ]; then
        echo "Could not find any resource manager. \
Is Slurm/TORQUE/PBS installed and on the PATH?"
        echo "An almost complete Slurm job script has been saved to \"${jobscript}\"."
        trap : 0
        exit 0
    fi
    # Only submit if a queue is specified
    if [ "${queue}" == "${queue_unspecified}" ]; then
        colorprint "Error: Cannot submit job as no queue is specified. \
An almost complete job script has been saved to \"${jobscript}\"." "red"
        exit 1
    fi
    # Submit the remote job from within the logs directory,
    # so that autogenerated files will be dumped there.
    colorprint "\nSubmitting job" "yellow"
    if [ "${resource_manager}" == 'slurm' ]; then
        jobid=$(cd "${logs_dir}" && sbatch "${jobscript}")
    elif [ "${resource_manager}" == 'torque' ]; then
        jobid=$(cd "${logs_dir}" && qsub "${jobscript}")
    fi
    jobid=$(echo "${jobid}" | awk '{print $NF}')
    jobid="${jobid%.*}"
    echo "Job ${jobid} (parameter file \"${params_rel}\") submitted to queue ${queue}"
    # Deactivate traps before exiting
    trap : 0
    # Invoke the watch utility on the submitted job
    # unless --no-watch was supplied.
    if [ "${no_watch}" == "False" ]; then
        # Invoke the watch utility on the submitted job
        echo "You can now kill (Ctrl-C) this script without cancelling the job"
        sleep 1
        "${concept}" -u watch "${jobid}"
    fi
    exit 0
else
    # Run locally
    if [[ "${nprocs}" == *':'* ]]; then
        colorprint "You may not specify a number of nodes when running locally" "red"
        exit 1
    fi
    # Construct a jobid that does not conflict
    # with the content of the logs dir.
    jobid=0
    while :; do
        if [ ! -f "${logs_dir}/${jobid}" ]; then
            break
        fi
        ((jobid += 1))
    done
    # Print start message
    echo
    if [ "${pure_python}" == "True" ]; then
        colorprint "Running CO𝘕CEPT in pure Python mode" "yellow" | tee    "${logs_dir}/${jobid}"
    else
        colorprint "Running CO𝘕CEPT" "yellow"                     | tee    "${logs_dir}/${jobid}"
    fi
    echo "Entry point:    \"${main_rel}\""                        | tee -a "${logs_dir}/${jobid}"
    if [ "${params_rel}" == "None" ]; then
        echo "Parameter file: ${params_rel}"                      | tee -a "${logs_dir}/${jobid}"
    else
        echo "Parameter file: \"${params_rel}\"${params_cp_info}" | tee -a "${logs_dir}/${jobid}"
    fi
    echo "Log file:       \"${logs_dir_rel}/${jobid}\""           | tee -a "${logs_dir}/${jobid}"
    # Prepare Python options
    if [ "${main_as_command}" == "yes" ]; then
        # Run main as Python command
        main_as_library="${main}"
        m_flag="-c"
    else
        if [ "${pure_python}" == "True" ]; then
            # Run mail as normal Python script
            main_as_library="${main}"
            m_flag=""
        else
            main_as_library="${main%.*}.so"
            if [ -f "${main_as_library}" ]; then
                # Run main as compiled library module
                main_as_library="$(basename "${main_as_library}")"
                m_flag="-m"
            else
                # Run main as normal Python script,
                # even though the CO𝘕CEPT modules are compiled.
                main_as_library="${main}"
                m_flag=""
            fi
        fi
    fi
    i_flag=""
    if [ "${interactive}" == "True" ]; then
        i_flag="-i"
    fi
    # Run the code. Print stdout and stderr to the terminal while at the
    # same time logging them to logs_dir/jobid. The stderr alone is also
    # logged to logs_dir/jobid_err.
    # We want the exit code of mpiexec, but it is not easily retrieved
    # due to the logging. We therefore print the exit code to a
    # temporary file which we then read and discard.
    exit_code_filename="${this_dir}/.exit_code_${start_time_human}"
    (("${mpiexec}" -n "${nprocs}"                             \
                   ${mpiexec_args}                            \
                   "${python}" -B ${i_flag}                   \
                               ${m_flag} "${main_as_library}" \
                               "params='${params}'"           \
                               "params_cp='${params_cp}'"     \
                               "jobid='${jobid}'"             \
     | tee -a "${logs_dir}/${jobid}";                         \
       echo "${PIPESTATUS[0]}" > "${exit_code_filename}"      \
     ) 3>&1 1>&2 2>&3 | tee -a "${logs_dir}/${jobid}"         \
                               "${logs_dir}/${jobid}_err") 3>&1 1>&2 2>&3
    # Get the exit code from the temporary file
    sleep_time=0.01
    sleep_max=1000
    slept=0
    while [ ! -f "${exit_code_filename}" ]; do
        sleep ${sleep_time}
        ((slept += 1))
        if [ ${slept} -ge ${sleep_max} ]; then
            break
        fi
    done
    exit_code=1
    if [ -f "${exit_code_filename}" ]; then
        exit_code="$(cat "${exit_code_filename}")"
        if [ -z "${exit_code}" ]; then
            exit_code=1
        fi
    fi
    # Run complete. Do cleanup.
    rm -f "${exit_code_filename}"
    if [ -f "${logs_dir}/${jobid}_err" ]; then
        if (   [ ! -s "${logs_dir}/${jobid}_err" ] \
            || ! grep -v '>>>' "${logs_dir}/${jobid}_err" >/dev/null 2>&1); then
            # Remove error log if empty
            rm "${logs_dir}/${jobid}_err"
        else
            colorprint "\nSome warnings/errors occured during CO𝘕CEPT run!\n\
Check the following error log for more information:\n\
\"${logs_dir}/${jobid}_err\"" "red" 2>&1 | tee -a "${logs_dir}/${jobid}" 1>&2
        fi
    fi
    # If the CO𝘕CEPT run exited erroneously, exit now
    if [ "${exit_code}" != "0" ]; then
        # Note that the real exit will be handled by the abort function
        exit ${exit_code}
    fi
    # Deactivate traps and exit
    trap : 0
    exit 0
fi
